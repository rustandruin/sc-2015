\section{Introduction}
\label{sec:intro}

The low-rank approximation to a data matrix $A$ that is provided by performing
a truncated SVD (singular value decomposition)---or PCA (principal component
analysis) or CX/CUR decompositions---is a very complicated object compared with
what is conveniently supported by traditional database
operations~\cite{Skillicorn07}. Recall that PCA finds mutually orthogonal
directions that maximize the variance captured by the factorization, and CX/CUR
provides an interpretable low-rank factorization by selecting a small number of
columns/rows from the original data matrix.  Described in more detail in
Section~\ref{sxn:low-rank-methods}, these low-rank approximation methods are
useful in scientific data analysis applications for exploratory data analysis
and for providing compact and interpretable representations of complex
matrix-based data, but their implementation at scale in distributed data
analytics frameworks such as Spark remains uninvestigated.

In this paper, we address the following research questions:
\begin{itemize}
  \item Can we successfully apply low rank matrix factorization methods such as
    CX and PCA to TB-scale scientific datasets in a contemporary data analytics
    framework such as Spark?

  \item What is the performance gap between C+MPI implementations of these
    factorization methods and Spark-based implementations? 

  \item How do Spark-based implementations scale on modern HPC and data-center
    hardware platforms?
\end{itemize}

We start with a description of matrix factorization algorithms in
Section~\ref{sxn:low-rank-methods}, followed by single node and multi-node
implementation details in Section~\ref{sec:implementation}. We review the
experimental setup for our performance tests in Section~\ref{sec:setup},
followed by results and discussion in Section~\ref{sec:results}.

